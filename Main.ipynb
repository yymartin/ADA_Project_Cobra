{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://www.occrp.org/en/panamapapers/database\n",
    "# TRUMP OFFSHORE INC. is good example to see all entities interacting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames / paths\n",
    "\n",
    "The data is separated for every leak source. For each leak source there is a folder containing the nodes of the graph, that can be of different types : <i>intermediary, officer, entity, address</i> (and <i>other</i> for paradise papers only). The folder also contains the edges of this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bahamas_folder = \"bahamas/\"\n",
    "panama_folder = \"panama/\"\n",
    "paradise_folder = \"paradise/\"\n",
    "offshore_folder = \"offshore/\"\n",
    "\n",
    "sources_names = [bahamas_folder[:-1], panama_folder[:-1], paradise_folder[:-1], offshore_folder[:-1]]\n",
    "\n",
    "panama_name = panama_folder + \"panama_papers\"\n",
    "paradise_name = paradise_folder + \"paradise_papers\"\n",
    "offshore_name = offshore_folder + \"offshore_leaks\"\n",
    "bahamas_name = bahamas_folder + \"bahamas_leaks\"\n",
    "\n",
    "edges_name = \".edges\"\n",
    "nodes_name = \".nodes.\"\n",
    "\n",
    "address_name = \"address\"\n",
    "intermediary_name = \"intermediary\"\n",
    "officer_name = \"officer\"\n",
    "entity_name = \"entity\"\n",
    "others_name = \"other\" # Only for paradise paper there is this extra entity\n",
    "\n",
    "usual_entity_names = [address_name, intermediary_name, officer_name, entity_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build local storage\n",
    "\n",
    "We store data in dictionnaries that map each leak source to its content, which is a dictionnary that maps each type of entity to the Dataframe containing its values. For example <b>d_sources[\"bahamas\"][\"officer\"]</b> is the Dataframe of officers coming from the bahamas leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_read_csv(filename) :\n",
    "    \"\"\" To have same rules when reading data from csv \"\"\"\n",
    "    return pd.read_csv(filename, dtype = str)\n",
    "\n",
    "def build_dict(source_name):\n",
    "    \"\"\"\n",
    "    Create a dictionnary for a certain source_name (among : Panama papers, Paradise papers...)\n",
    "    that maps to each entity name (among : Officer, Intermediary, Address...)\n",
    "    the content of the csv from source_name for this entity\n",
    "    \"\"\"\n",
    "    d = {en : my_read_csv(source_name + nodes_name + en + \".csv\") for en in usual_entity_names}\n",
    "    \n",
    "    if source_name == paradise_name: # Extra \"other\" entity in paradise papers\n",
    "        d[others_name] = my_read_csv(source_name + nodes_name + others_name + \".csv\")\n",
    "    \n",
    "    #Add edges\n",
    "    d[\"edges\"] = my_read_csv(source_name + edges_name + \".csv\")\n",
    "              \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dictionnary, that maps each source its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sources = dict()\n",
    "d_sources[\"bahamas\"] = build_dict(bahamas_name)\n",
    "d_sources[\"panama\"] = build_dict(panama_name)\n",
    "d_sources[\"paradise\"] = build_dict(paradise_name)\n",
    "d_sources[\"offshore\"] = build_dict(offshore_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node_id', 'name', 'jurisdiction', 'jurisdiction_description',\n",
       "       'country_codes', 'countries', 'incorporation_date', 'inactivation_date',\n",
       "       'struck_off_date', 'closed_date', 'ibcRUC', 'status', 'company_type',\n",
       "       'service_provider', 'sourceID', 'valid_until', 'note'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sources['panama']['entity'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting familiar with the data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some coloring for printing\n",
    "\n",
    "Keep the same coloring during the project, it makes data very easily readable once you get familiar with the coloring !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mbahamas\u001b[0m\n",
      "\u001b[92mparadise\u001b[0m\n",
      "\u001b[91mpanama\u001b[0m\n",
      "\u001b[94moffshore\u001b[0m\n",
      "\u001b[1mUnknown source\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "BLUE = '\\033[94m'\n",
    "GREEN = '\\033[92m'\n",
    "YELLOW = '\\033[93m'\n",
    "RED = '\\033[91m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "color_dict = dict()\n",
    "color_dict[\"bahamas\"] = YELLOW\n",
    "color_dict[\"paradise\"] = GREEN\n",
    "color_dict[\"panama\"] = RED\n",
    "color_dict[\"offshore\"] = BLUE\n",
    "\n",
    "def color(str):\n",
    "    \"\"\"\n",
    "    Returns the str given in the color of the source it is from \n",
    "    (the str must contain source name)\n",
    "    \"\"\"\n",
    "    for source in color_dict.keys():\n",
    "        if source in str:\n",
    "            return color_dict[source] + str + END \n",
    "        \n",
    "    return BOLD + str + END #Default color is BOLD\n",
    "\n",
    "for name, _ in color_dict.items():\n",
    "    print(color(name))\n",
    "print(color(\"Unknown source\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what data source misses which column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "Node type address misses 10 columns, namely :  ['labels(n)', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type intermediary misses 10 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'company_type']\n",
      "Node type officer misses 11 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type entity misses 3 columns, namely :  ['labels(n)', 'address', 'type']\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "Node type address misses 10 columns, namely :  ['labels(n)', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type intermediary misses 11 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type officer misses 10 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'company_type']\n",
      "Node type entity misses 3 columns, namely :  ['labels(n)', 'address', 'type']\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "Node type address misses 10 columns, namely :  ['labels(n)', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type intermediary misses 10 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'company_type']\n",
      "Node type officer misses 11 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type entity misses 3 columns, namely :  ['labels(n)', 'address', 'type']\n",
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "Node type entity misses 2 columns, namely :  ['inactivation_date', 'struck_off_date']\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "Node type intermediary misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "Node type entity misses 2 columns, namely :  ['inactivation_date', 'struck_off_date']\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "Node type officer misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "Node type officer misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n",
      "Node type entity misses 2 columns, namely :  ['inactivation_date', 'struck_off_date']\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n",
      "Node type intermediary misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for source, dict_data in d_sources.items():\n",
    "    for source_compare, dict_data_compare in d_sources.items():\n",
    "        print(\"\\n\", color(source_compare), \"missing columns from source :\", color(source))\n",
    "        for entity in usual_entity_names:\n",
    "            missing_columns = []\n",
    "            for col in dict_data[entity].columns:\n",
    "                if not col in dict_data_compare[entity].columns:\n",
    "                    missing_columns.append(col)\n",
    "            if(len(missing_columns) > 0):\n",
    "                print(\"Node type\", entity, \"misses\", len(missing_columns), \"columns, namely : \", missing_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that <span style=\"color:orange\">bahamas</span> is the most \"complete\" source, in the sense it is the one that has the biggest number of columns missing in the others. We will therefore use it to explore the content of columns. *'inactivation_date'* and  *'struck_off_date'* columns from entity will then be explored in <span style=\"color:red\">panama</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special case : Paradise paper, <i>other</i> node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node_id', 'name', 'country_codes', 'countries', 'sourceID',\n",
       "       'valid_until', 'note'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sources[\"paradise\"][\"other\"].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SourceID in different sources\n",
    "\n",
    "We see paradise papers is the only source that has different sourceID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source : \u001b[93mbahamas\u001b[0m\n",
      "Node : address 1 different sourceID :\n",
      "Node : intermediary 1 different sourceID :\n",
      "Node : officer 1 different sourceID :\n",
      "Node : entity 1 different sourceID :\n",
      "\n",
      "Source : \u001b[91mpanama\u001b[0m\n",
      "Node : address 1 different sourceID :\n",
      "Node : intermediary 1 different sourceID :\n",
      "Node : officer 1 different sourceID :\n",
      "Node : entity 1 different sourceID :\n",
      "\n",
      "Source : \u001b[92mparadise\u001b[0m\n",
      "Node : address 7 different sourceID :\n",
      "Node : intermediary 5 different sourceID :\n",
      "Node : officer 9 different sourceID :\n",
      "Node : entity 9 different sourceID :\n",
      "\n",
      "Source : \u001b[94moffshore\u001b[0m\n",
      "Node : address 1 different sourceID :\n",
      "Node : intermediary 1 different sourceID :\n",
      "Node : officer 1 different sourceID :\n",
      "Node : entity 1 different sourceID :\n"
     ]
    }
   ],
   "source": [
    "for source, dict_data in d_sources.items():\n",
    "    print(\"\\nSource :\", color(source))\n",
    "    for entity in usual_entity_names:\n",
    "        value_count =  dict_data[entity][\"sourceID\"].value_counts()\n",
    "        print(\"Node :\", entity, len(value_count), \"different sourceID :\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if node_id is a good index for Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_id isn't unique between nodes from source \u001b[94moffshore\u001b[0m\n",
      "node_id is unique between unique nodes from all sources\n"
     ]
    }
   ],
   "source": [
    "merged_node_id = pd.Series()\n",
    "\n",
    "for source, dict_data in d_sources.items():\n",
    "    merged_node_id_source = pd.Series()\n",
    "    for entity in usual_entity_names:\n",
    "        \n",
    "        merged_node_id_source = merged_node_id_source.append(dict_data[entity][\"node_id\"], ignore_index = True)\n",
    "        \n",
    "        if not dict_data[entity][\"node_id\"].is_unique:\n",
    "            print(\"node_id isn't unique for source\", color(source, \"node\", entity))\n",
    "                  \n",
    "    if not merged_node_id_source.is_unique:\n",
    "        print(\"node_id isn't unique between nodes from source\", color(source))\n",
    "    \n",
    "    merged_node_id = merged_node_id.append(merged_node_id_source.drop_duplicates())\n",
    "\n",
    "if merged_node_id.is_unique:\n",
    "    print(\"node_id is unique between unique nodes from all sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for each node type indepently node_id is a good index. Therefore (node_id, node_type) could be a good index (node_type being amond officer, intermediary...)\n",
    "\n",
    "Now explore nodes with same node_id in offshore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1maddress\u001b[0m \u001b[1mintermediary\u001b[0m\n",
      "\u001b[1maddress\u001b[0m \u001b[1mofficer\u001b[0m\n",
      "\u001b[1maddress\u001b[0m \u001b[1mentity\u001b[0m\n",
      "\u001b[1mintermediary\u001b[0m \u001b[1mofficer\u001b[0m\n",
      "Intersection of \u001b[1mintermediary\u001b[0m and \u001b[1mofficer\u001b[0m count is :\n",
      "name_intermediary             1139\n",
      "country_codes_intermediary    1139\n",
      "countries_intermediary        1139\n",
      "status                           0\n",
      "sourceID_intermediary         1139\n",
      "valid_until_intermediary      1139\n",
      "note_intermediary                0\n",
      "name_officer                  1139\n",
      "country_codes_officer         1139\n",
      "countries_officer             1139\n",
      "sourceID_officer              1139\n",
      "valid_until_officer           1139\n",
      "note_officer                     0\n",
      "dtype: int64\n",
      "\u001b[1mintermediary\u001b[0m \u001b[1mentity\u001b[0m\n",
      "\u001b[1mofficer\u001b[0m \u001b[1mentity\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(usual_entity_names)):\n",
    "    for j in range(i+1, len(usual_entity_names)):\n",
    "\n",
    "        left_node = usual_entity_names[i]\n",
    "        node = usual_entity_names[j]\n",
    "        print(color(left_node), color(node))\n",
    "        \n",
    "        if left_node != node:\n",
    "\n",
    "            left = d_sources[\"offshore\"][left_node].set_index(\"node_id\")\n",
    "            right = d_sources[\"offshore\"][node].set_index(\"node_id\")\n",
    "\n",
    "            intersection = left.join(right, on = \"node_id\", how = 'inner', \\\n",
    "                                     lsuffix = \"_\" + left_node,rsuffix = \"_\" + node)\n",
    "\n",
    "            if not intersection.empty:\n",
    "                print(\"Intersection of\", color(left_node), \"and\", color(node), \"count is :\")\n",
    "                print(intersection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the intersection on offshore is between officer and intermediary nodes. Let's see if they are the same values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = d_sources[\"offshore\"][\"officer\"].set_index(\"node_id\")\n",
    "right = d_sources[\"offshore\"][\"intermediary\"].set_index(\"node_id\")\n",
    "\n",
    "intersection = left.join(right, on = \"node_id\", how = 'inner', lsuffix = \"_officer\",rsuffix = \"_interm\")\n",
    "\n",
    "intersection.loc[intersection[\"name_officer\"]!= intersection[\"name_interm\"]].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we understand that if someone appears in two different node types, it means he has two roles. This is why in further analysis we will store the pair (node_id, role) as index, because it is unique. We have to add a column to nodes, containing the node type, let's call it label. We saw in the column exploration that bahamas has an equivalent column *labels(n)*, that the other's don't, we'll rename it to *label*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in [\"paradise\", \"offshore\", \"panama\"]:\n",
    "    for role in usual_entity_names:\n",
    "        d_sources[source][role][\"label\"] = role\n",
    "\n",
    "for role in usual_entity_names:\n",
    "        d_sources[\"bahamas\"][role].rename(columns={\"labels(n)\": \"label\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check bahamas label is consistent (only one value for each type of node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mbahamas\u001b[0m address number of different values : 1\n",
      "\u001b[93mbahamas\u001b[0m intermediary number of different values : 1\n",
      "\u001b[93mbahamas\u001b[0m officer number of different values : 1\n",
      "\u001b[93mbahamas\u001b[0m entity number of different values : 1\n"
     ]
    }
   ],
   "source": [
    "for role in usual_entity_names:\n",
    "    print(color(\"bahamas\"), role, \"number of different values :\", d_sources['bahamas'][role][\"label\"].value_counts().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_clean = copy.deepcopy(d_sources)\n",
    "d_clean[\"bahamas\"]['address'] = d_sources[\"bahamas\"]['address'][['country_codes', 'node_id']]\n",
    "d_clean[\"bahamas\"]['address']['file'] = 'bahamas'\n",
    "d_clean[\"bahamas\"]['address']['type'] = 'address'\n",
    "\n",
    "d_clean[\"panama\"]['address'] = d_sources[\"panama\"]['address'][['country_codes', 'node_id']]\n",
    "d_clean[\"bahamas\"]['address']['file'] = 'panama'\n",
    "d_clean[\"panama\"]['address']['type'] = 'address'\n",
    "\n",
    "d_clean[\"paradise\"]['address'] = d_sources[\"paradise\"]['address'][['country_codes', 'node_id']]\n",
    "d_clean[\"bahamas\"]['address']['file'] = 'paradise'\n",
    "d_clean[\"paradise\"]['address']['type'] = 'address'\n",
    "\n",
    "d_clean[\"offshore\"]['address'] = d_sources[\"offshore\"]['address'][['country_codes', 'node_id']]\n",
    "d_clean[\"bahamas\"]['address']['file'] = 'offshore'\n",
    "d_clean[\"offshore\"]['address']['type'] = 'address'\n",
    "\n",
    "\n",
    "d_clean['bahamas']['entity'] = d_sources['bahamas']['entity'][['node_id','name','jurisdiction','incorporation_date']]\n",
    "d_clean[\"bahamas\"]['entity']['file'] = 'bahamas'\n",
    "d_clean[\"bahamas\"]['entity']['type'] = 'entity'\n",
    "\n",
    "d_clean['panama']['entity'] = d_sources['panama']['entity'][['node_id','name','jurisdiction','country_codes','incorporation_date']]\n",
    "d_clean[\"panama\"]['entity']['file'] = 'panama'\n",
    "d_clean[\"panama\"]['entity']['type'] = 'entity'\n",
    "\n",
    "d_clean['paradise']['entity'] = d_sources['paradise']['entity'][['node_id', 'name','jurisdiction','country_codes','incorporation_date']]\n",
    "d_clean[\"paradise\"]['entity']['file'] = 'paradise'\n",
    "d_clean[\"paradise\"]['entity']['type'] = 'entity'\n",
    "\n",
    "d_clean['offshore']['entity'] = d_sources['offshore']['entity'][['node_id', 'name','jurisdiction','country_codes','incorporation_date']]\n",
    "d_clean[\"offshore\"]['entity']['file'] = 'offshore'\n",
    "d_clean[\"offshore\"]['entity']['type'] = 'entity'\n",
    "\n",
    "d_clean['bahamas']['intermediary'] = d_sources['bahamas']['intermediary'][['node_id', 'country_codes','name']]\n",
    "d_clean[\"bahamas\"]['intermediary']['file'] = 'bahamas'\n",
    "d_clean[\"bahamas\"]['intermediary']['type'] = 'intermediary'\n",
    "\n",
    "d_clean['panama']['intermediary'] = d_sources['panama']['intermediary'][['node_id', 'country_codes','name']]\n",
    "d_clean[\"panama\"]['intermediary']['file'] = 'panama'\n",
    "d_clean[\"panama\"]['intermediary']['type'] = 'intermediary'\n",
    "\n",
    "d_clean['paradise']['intermediary'] = d_sources['paradise']['intermediary'][['node_id', 'country_codes','name']]\n",
    "d_clean[\"paradise\"]['intermediary']['file'] = 'paradise'\n",
    "d_clean[\"paradise\"]['intermediary']['type'] = 'intermediary'\n",
    "\n",
    "d_clean['offshore']['intermediary'] = d_sources['offshore']['intermediary'][['node_id', 'country_codes','name']]\n",
    "d_clean[\"offshore\"]['intermediary']['file'] = 'offshore'\n",
    "d_clean[\"offshore\"]['intermediary']['type'] = 'intermediary'\n",
    "\n",
    "d_clean['bahamas']['officer'] = d_sources['bahamas']['officer'][['node_id', 'country_codes','name']]\n",
    "d_clean[\"bahamas\"]['officer']['file'] = 'bahamas'\n",
    "d_clean[\"bahamas\"]['officer']['type'] = 'officer'\n",
    "\n",
    "d_clean['panama']['officer'] = d_sources['panama']['officer'][['node_id', 'country_codes','name']]\n",
    "d_clean[\"panama\"]['officer']['file'] = 'panama'\n",
    "d_clean[\"panama\"]['officer']['type'] = 'officer'\n",
    "\n",
    "d_clean['paradise']['officer'] = d_sources['paradise']['officer'][['node_id', 'country_codes','name']]\n",
    "d_clean[\"paradise\"]['officer']['file'] = 'paradise'\n",
    "d_clean[\"paradise\"]['officer']['type'] = 'officer'\n",
    "\n",
    "d_clean['offshore']['officer'] = d_sources['offshore']['officer'][['node_id', 'country_codes','name']]\n",
    "d_clean[\"offshore\"]['officer']['file'] = 'offshore'\n",
    "d_clean[\"offshore\"]['officer']['type'] = 'officer'\n",
    "\n",
    "d_clean['paradise']['other'] = d_sources['paradise']['other'][['node_id', 'country_codes','name']]\n",
    "d_clean[\"paradise\"]['other']['file'] = 'paradise'\n",
    "d_clean[\"paradise\"]['other']['type'] = 'other'\n",
    "\n",
    "d_clean['bahamas']['edges'] = d_sources['bahamas']['edges'][['node_1','node_2', 'rel_type', 'start_date', 'end_date']]\n",
    "d_clean['bahamas']['edges']['file'] = 'bahamas'\n",
    "d_clean['panama']['edges'] = d_sources['panama']['edges'][['START_ID', 'END_ID', 'TYPE', 'start_date', 'end_date']]\n",
    "d_clean['panama']['edges']['file'] = 'panama'\n",
    "d_clean['paradise']['edges'] = d_sources['paradise']['edges'][['START_ID', 'END_ID', 'TYPE', 'start_date', 'end_date']]\n",
    "d_clean['paradise']['edges']['file'] = 'paradise'\n",
    "d_clean['offshore']['edges'] = d_sources['offshore']['edges'][['START_ID', 'END_ID', 'TYPE', 'start_date', 'end_date']]\n",
    "d_clean['offshore']['edges']['file'] = 'offshore'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create node dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(columns=['node_id','file','type','name','country_codes', 'jurisdiction', 'incorporation_date'])\n",
    "nodes = nodes.append([d_clean[\"bahamas\"]['address'],d_clean[\"panama\"]['address'],d_clean[\"paradise\"]['address'],d_clean[\"offshore\"]['address']], sort=False)\n",
    "nodes = nodes.append([d_clean[\"bahamas\"]['entity'],d_clean[\"panama\"]['entity'],d_clean[\"paradise\"]['entity'],d_clean[\"offshore\"]['entity']], sort=False)\n",
    "nodes = nodes.append([d_clean[\"bahamas\"]['intermediary'],d_clean[\"panama\"]['intermediary'],d_clean[\"paradise\"]['intermediary'],d_clean[\"offshore\"]['intermediary']], sort=False)\n",
    "nodes = nodes.append([d_clean[\"bahamas\"]['officer'],d_clean[\"panama\"]['officer'],d_clean[\"paradise\"]['officer'],d_clean[\"offshore\"]['officer']], sort=False)\n",
    "nodes = nodes.append(d_clean['paradise']['other'], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create edges dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_clean['bahamas']['edges'].columns=['START_ID', 'END_ID', 'rel_type', 'start_date', 'end_date','file']\n",
    "\n",
    "edges = pd.DataFrame(columns=['START_ID', 'END_ID', 'rel_type', 'start_date', 'end_date','file'])\n",
    "edges = edges.append([d_clean['bahamas']['edges'], d_clean['panama']['edges'], d_clean['paradise']['edges'], d_clean['offshore']['edges']], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries for countries and jurisdictions\n",
    "\n",
    "These dictionaries map the abrevation of countries to their full name, this way we can drop the longer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = dict(zip(d_sources['bahamas']['address']['country_codes'], d_sources['bahamas']['address']['countries']))\n",
    "countries.update(dict(zip(d_sources['panama']['address']['country_codes'], d_sources['panama']['address']['countries'])))\n",
    "countries.update(dict(zip(d_sources['paradise']['address']['country_codes'], d_sources['paradise']['address']['countries'])))\n",
    "countries.update(dict(zip(d_sources['offshore']['address']['country_codes'], d_sources['offshore']['address']['countries'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "jurisdictions = dict(zip(d_sources['bahamas']['entity']['jurisdiction'], d_sources['bahamas']['entity']['jurisdiction_description']))\n",
    "jurisdictions.update(dict(zip(d_sources['panama']['entity']['jurisdiction'], d_sources['panama']['entity']['jurisdiction_description'])))\n",
    "jurisdictions.update(dict(zip(d_sources['paradise']['entity']['jurisdiction'], d_sources['paradise']['entity']['jurisdiction_description'])))\n",
    "jurisdictions.update(dict(zip(d_sources['offshore']['entity']['jurisdiction'], d_sources['offshore']['entity']['jurisdiction_description'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : \n",
    "- some have file with NaN ???\n",
    "- What to do with those with no country_code ?\n",
    "- What to do with those with no incorporation date ? \n",
    "- Define difference between jurisdiction and country_code\n",
    "- definde node_id/type as index\n",
    "- keep validity date ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>file</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>country_codes</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>incorporation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1909605</td>\n",
       "      <td>1535201</td>\n",
       "      <td>1909605</td>\n",
       "      <td>1534558</td>\n",
       "      <td>1185431</td>\n",
       "      <td>785124</td>\n",
       "      <td>771353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1908466</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1252082</td>\n",
       "      <td>4135</td>\n",
       "      <td>80</td>\n",
       "      <td>18286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>95328</td>\n",
       "      <td>paradise</td>\n",
       "      <td>entity</td>\n",
       "      <td>THE BEARER</td>\n",
       "      <td>MLT</td>\n",
       "      <td>BAH</td>\n",
       "      <td>02-JAN-1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>644581</td>\n",
       "      <td>785124</td>\n",
       "      <td>70871</td>\n",
       "      <td>129661</td>\n",
       "      <td>209634</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        node_id      file     type        name country_codes jurisdiction  \\\n",
       "count   1909605   1535201  1909605     1534558       1185431       785124   \n",
       "unique  1908466         4        5     1252082          4135           80   \n",
       "top       95328  paradise   entity  THE BEARER           MLT          BAH   \n",
       "freq          2    644581   785124       70871        129661       209634   \n",
       "\n",
       "       incorporation_date  \n",
       "count              771353  \n",
       "unique              18286  \n",
       "top           02-JAN-1998  \n",
       "freq                 1368  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edges with no end_date are still true until \"date of validity\"\n",
    "- Turn start/end date to DATE format, check outliers/typos\n",
    "- Study duff between rel_type and TYPE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>START_ID</th>\n",
       "      <th>END_ID</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>file</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3142523</td>\n",
       "      <td>3142523</td>\n",
       "      <td>249190</td>\n",
       "      <td>937487</td>\n",
       "      <td>268589</td>\n",
       "      <td>3142523</td>\n",
       "      <td>2893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1054794</td>\n",
       "      <td>1224551</td>\n",
       "      <td>9</td>\n",
       "      <td>23760</td>\n",
       "      <td>13461</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>54662</td>\n",
       "      <td>236724</td>\n",
       "      <td>intermediary_of</td>\n",
       "      <td>31-DEC-1969</td>\n",
       "      <td>30-SEP-2012</td>\n",
       "      <td>paradise</td>\n",
       "      <td>officer_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36373</td>\n",
       "      <td>37338</td>\n",
       "      <td>175876</td>\n",
       "      <td>1848</td>\n",
       "      <td>9663</td>\n",
       "      <td>1657838</td>\n",
       "      <td>1630705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       START_ID   END_ID         rel_type   start_date     end_date      file  \\\n",
       "count   3142523  3142523           249190       937487       268589   3142523   \n",
       "unique  1054794  1224551                9        23760        13461         4   \n",
       "top       54662   236724  intermediary_of  31-DEC-1969  30-SEP-2012  paradise   \n",
       "freq      36373    37338           175876         1848         9663   1657838   \n",
       "\n",
       "              TYPE  \n",
       "count      2893333  \n",
       "unique           8  \n",
       "top     officer_of  \n",
       "freq       1630705  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
