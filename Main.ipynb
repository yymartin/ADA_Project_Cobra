{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://www.occrp.org/en/panamapapers/database\n",
    "# TRUMP OFFSHORE INC. is good example to see all entities interacting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames / paths\n",
    "\n",
    "The data is separated for every leak source. For each leak source there is a folder containing the nodes of the graph, that can be of different types : <i>intermediary, officer, entity, address</i> (and <i>other</i> for paradise papers only). The folder also contains the edges of this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bahamas_folder = \"bahamas/\"\n",
    "panama_folder = \"panama/\"\n",
    "paradise_folder = \"paradise/\"\n",
    "offshore_folder = \"offshore/\"\n",
    "\n",
    "sources_names = [bahamas_folder[:-1], panama_folder[:-1], paradise_folder[:-1], offshore_folder[:-1]]\n",
    "\n",
    "panama_name = panama_folder + \"panama_papers\"\n",
    "paradise_name = paradise_folder + \"paradise_papers\"\n",
    "offshore_name = offshore_folder + \"offshore_leaks\"\n",
    "bahamas_name = bahamas_folder + \"bahamas_leaks\"\n",
    "\n",
    "edges_name = \".edges\"\n",
    "nodes_name = \".nodes.\"\n",
    "\n",
    "address_name = \"address\"\n",
    "intermediary_name = \"intermediary\"\n",
    "officer_name = \"officer\"\n",
    "entity_name = \"entity\"\n",
    "others_name = \"other\" # Only for paradise paper there is this extra entity\n",
    "\n",
    "usual_entity_names = [address_name, intermediary_name, officer_name, entity_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build local storage\n",
    "\n",
    "We store data in dictionnaries that map each leak source to its content, which is a dictionnary that maps each type of entity to the Dataframe containing its values. For example <b>d_sources[\"bahamas\"][\"officer\"]</b> is the Dataframe of officers coming from the bahamas leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_read_csv(filename) :\n",
    "    \"\"\" To have same rules when reading data from csv \"\"\"\n",
    "    return pd.read_csv(filename, dtype = np.str)\n",
    "\n",
    "def build_dict(source_name):\n",
    "    \"\"\"\n",
    "    Create a dictionnary for a certain source_name (among : Panama papers, Paradise papers...)\n",
    "    that maps to each entity name (among : Officer, Intermediary, Address...)\n",
    "    the content of the csv from source_name for this entity\n",
    "    \"\"\"\n",
    "    d = {en : my_read_csv(source_name + nodes_name + en + \".csv\") for en in usual_entity_names}\n",
    "    \n",
    "    if source_name == paradise_name: # Extra \"other\" entity in paradise papers\n",
    "        d[others_name] = my_read_csv(source_name + nodes_name + others_name + \".csv\")\n",
    "    \n",
    "    #Add edges\n",
    "    d[\"edges\"] = my_read_csv(source_name + edges_name + \".csv\")\n",
    "              \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dictionnary, that maps each source its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sources = dict()\n",
    "d_sources[\"bahamas\"] = build_dict(bahamas_name)\n",
    "d_sources[\"panama\"] = build_dict(panama_name)\n",
    "d_sources[\"paradise\"] = build_dict(paradise_name)\n",
    "d_sources[\"offshore\"] = build_dict(offshore_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting familiar with the data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some coloring for printing\n",
    "\n",
    "Keep the same coloring during the project, it makes data very easily readable once you get familiar with the coloring !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mbahamas\u001b[0m\n",
      "\u001b[92mparadise\u001b[0m\n",
      "\u001b[91mpanama\u001b[0m\n",
      "\u001b[94moffshore\u001b[0m\n",
      "\u001b[1mUnknown source\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "BLUE = '\\033[94m'\n",
    "GREEN = '\\033[92m'\n",
    "YELLOW = '\\033[93m'\n",
    "RED = '\\033[91m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "color_dict = dict()\n",
    "color_dict[\"bahamas\"] = YELLOW\n",
    "color_dict[\"paradise\"] = GREEN\n",
    "color_dict[\"panama\"] = RED\n",
    "color_dict[\"offshore\"] = BLUE\n",
    "\n",
    "def color(str):\n",
    "    \"\"\"\n",
    "    Returns the str given in the color of the source it is from \n",
    "    (the str must contain source name)\n",
    "    \"\"\"\n",
    "    for source in color_dict.keys():\n",
    "        if source in str:\n",
    "            return color_dict[source] + str + END \n",
    "        \n",
    "    return BOLD + str + END #Default color is BOLD\n",
    "\n",
    "for name, _ in color_dict.items():\n",
    "    print(color(name))\n",
    "print(color(\"Unknown source\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what data source misses which column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "Node type address misses 10 columns, namely :  ['labels(n)', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type intermediary misses 10 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'company_type']\n",
      "Node type officer misses 11 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type entity misses 3 columns, namely :  ['labels(n)', 'address', 'type']\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "Node type address misses 10 columns, namely :  ['labels(n)', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type intermediary misses 11 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type officer misses 10 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'company_type']\n",
      "Node type entity misses 3 columns, namely :  ['labels(n)', 'address', 'type']\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "Node type address misses 10 columns, namely :  ['labels(n)', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type intermediary misses 10 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'company_type']\n",
      "Node type officer misses 11 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type entity misses 3 columns, namely :  ['labels(n)', 'address', 'type']\n",
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "Node type entity misses 2 columns, namely :  ['inactivation_date', 'struck_off_date']\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "Node type intermediary misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "Node type entity misses 2 columns, namely :  ['inactivation_date', 'struck_off_date']\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "Node type officer misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "Node type officer misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n",
      "Node type entity misses 2 columns, namely :  ['inactivation_date', 'struck_off_date']\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n",
      "Node type intermediary misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for source, dict_data in d_sources.items():\n",
    "    for source_compare, dict_data_compare in d_sources.items():\n",
    "        print(\"\\n\", color(source_compare), \"missing columns from source :\", color(source))\n",
    "        for entity in usual_entity_names:\n",
    "            missing_columns = []\n",
    "            for col in dict_data[entity].columns:\n",
    "                if not col in dict_data_compare[entity].columns:\n",
    "                    missing_columns.append(col)\n",
    "            if(len(missing_columns) > 0):\n",
    "                print(\"Node type\", entity, \"misses\", len(missing_columns), \"columns, namely : \", missing_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that <span style=\"color:orange\">bahamas</span> is the most \"complete\" source, in the sense it is the one that has the biggest number of columns missing in the others. We will therefore use it to explore the content of columns. *'inactivation_date'* and  *'struck_off_date'* columns from entity will then be explored in <span style=\"color:red\">panama</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special case : Paradise paper, <i>other</i> entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node_id', 'name', 'country_codes', 'countries', 'sourceID',\n",
       "       'valid_until', 'note'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sources[\"paradise\"][\"other\"].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SourceID in different sources\n",
    "\n",
    "We see paradise papers is the only source that has different sourceID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source : \u001b[93mbahamas\u001b[0m\n",
      "Node : address 1 different sourceID :\n",
      "Node : intermediary 1 different sourceID :\n",
      "Node : officer 1 different sourceID :\n",
      "Node : entity 1 different sourceID :\n",
      "\n",
      "Source : \u001b[91mpanama\u001b[0m\n",
      "Node : address 1 different sourceID :\n",
      "Node : intermediary 1 different sourceID :\n",
      "Node : officer 1 different sourceID :\n",
      "Node : entity 1 different sourceID :\n",
      "\n",
      "Source : \u001b[92mparadise\u001b[0m\n",
      "Node : address 7 different sourceID :\n",
      "Node : intermediary 5 different sourceID :\n",
      "Node : officer 9 different sourceID :\n",
      "Node : entity 9 different sourceID :\n",
      "\n",
      "Source : \u001b[94moffshore\u001b[0m\n",
      "Node : address 1 different sourceID :\n",
      "Node : intermediary 1 different sourceID :\n",
      "Node : officer 1 different sourceID :\n",
      "Node : entity 1 different sourceID :\n"
     ]
    }
   ],
   "source": [
    "for source, dict_data in d_sources.items():\n",
    "    print(\"\\nSource :\", color(source))\n",
    "    for entity in usual_entity_names:\n",
    "        value_count =  dict_data[entity][\"sourceID\"].value_counts()\n",
    "        print(\"Node :\", entity, len(value_count), \"different sourceID :\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if node_id is a good index for Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_node_id = pd.Series()\n",
    "\n",
    "for source, dict_data in d_sources.items():\n",
    "    for entity in usual_entity_names:\n",
    "        merged_node_id = merged_node_id.append(dict_data[entity][\"node_id\"], ignore_index = True)\n",
    "        if not dict_data[entity][\"node_id\"].is_unique:\n",
    "            print(\"node_id isn't unique for source\", source, \"node\", entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for each source indepently node_id is a good index. Unfortunately, it doesn't hold if we merge sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_node_id.value_counts().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels(n)</th>\n",
       "      <th>valid_until</th>\n",
       "      <th>country_codes</th>\n",
       "      <th>countries</th>\n",
       "      <th>node_id</th>\n",
       "      <th>sourceID</th>\n",
       "      <th>address</th>\n",
       "      <th>name</th>\n",
       "      <th>jurisdiction_description</th>\n",
       "      <th>service_provider</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>incorporation_date</th>\n",
       "      <th>ibcRUC</th>\n",
       "      <th>type</th>\n",
       "      <th>status</th>\n",
       "      <th>company_type</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25262</td>\n",
       "      <td>25262</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>25262</td>\n",
       "      <td>25262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>25262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>[\"Officer\"]</td>\n",
       "      <td>The Bahamas Leaks data is current through earl...</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Spain</td>\n",
       "      <td>22006856</td>\n",
       "      <td>Bahamas Leaks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLEMENTI LIMITED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Record manually added from leaked documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>25262</td>\n",
       "      <td>25262</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>25262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          labels(n)                                        valid_until  \\\n",
       "count         25262                                              25262   \n",
       "unique            1                                                  1   \n",
       "top     [\"Officer\"]  The Bahamas Leaks data is current through earl...   \n",
       "freq          25262                                              25262   \n",
       "\n",
       "       country_codes countries   node_id       sourceID  address  \\\n",
       "count             81        81     25262          25262      0.0   \n",
       "unique            23        23     25262              1      0.0   \n",
       "top              ESP     Spain  22006856  Bahamas Leaks      NaN   \n",
       "freq              20        20         1          25262      NaN   \n",
       "\n",
       "                    name  jurisdiction_description  service_provider  \\\n",
       "count              25262                       0.0               0.0   \n",
       "unique              7143                       0.0               0.0   \n",
       "top     CLEMENTI LIMITED                       NaN               NaN   \n",
       "freq                1110                       NaN               NaN   \n",
       "\n",
       "        jurisdiction  closed_date  incorporation_date  ibcRUC  type  status  \\\n",
       "count            0.0          0.0                 0.0     0.0   0.0     0.0   \n",
       "unique           0.0          0.0                 0.0     0.0   0.0     0.0   \n",
       "top              NaN          NaN                 NaN     NaN   NaN     NaN   \n",
       "freq             NaN          NaN                 NaN     NaN   NaN     NaN   \n",
       "\n",
       "        company_type                                         note  \n",
       "count            0.0                                           83  \n",
       "unique           0.0                                            3  \n",
       "top              NaN  Record manually added from leaked documents  \n",
       "freq             NaN                                           81  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bahamas_officer = d_sources[\"bahamas\"][\"officer\"]\n",
    "\n",
    "bahamas_officer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
