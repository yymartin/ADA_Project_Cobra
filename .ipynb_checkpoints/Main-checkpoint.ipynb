{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A time Story of offshore Societies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the aim of this project in the README file.\n",
    "\n",
    "Our work is based on 4 databases, namely the *bahamas leaks*, the *panama papers*, the *offshore leaks* and the *paradise papers*. They all contain csv files with all the data of a graph : nodes (one file for each type of node), and edges. We merged all these files in this notebook.\n",
    "\n",
    "You will see all the steps of our data exploration. In the end our objective is to arrive to two Dataframe, one containing all the nodes and the relevant information, and one containing the edges with relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx #For graphs\n",
    "import copy\n",
    "import warnings\n",
    "from datetime import *\n",
    "import dateutil.parser\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://www.occrp.org/en/panamapapers/database\n",
    "# TRUMP OFFSHORE INC. is good example to see all entities interacting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames / paths\n",
    "\n",
    "The data is separated for every leak source. For each leak source there is a folder containing the nodes of the graph, that can be of different types : <i>intermediary, officer, entity, address</i> (and <i>other</i> for paradise papers only). The folder also contains the edges of this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bahamas_folder = \"bahamas/\"\n",
    "panama_folder = \"panama/\"\n",
    "paradise_folder = \"paradise/\"\n",
    "offshore_folder = \"offshore/\"\n",
    "\n",
    "sources_names = ['bahamas', 'panama', 'paradise', 'offshore']\n",
    "\n",
    "panama_name = panama_folder + \"panama_papers\"\n",
    "paradise_name = paradise_folder + \"paradise_papers\"\n",
    "offshore_name = offshore_folder + \"offshore_leaks\"\n",
    "bahamas_name = bahamas_folder + \"bahamas_leaks\"\n",
    "\n",
    "edges_name = \".edges\"\n",
    "nodes_name = \".nodes.\"\n",
    "\n",
    "address_name = \"address\"\n",
    "intermediary_name = \"intermediary\"\n",
    "officer_name = \"officer\"\n",
    "entity_name = \"entity\"\n",
    "others_name = \"other\" # Only for paradise paper there is this extra entity\n",
    "\n",
    "usual_entity_names = [address_name, intermediary_name, officer_name, entity_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build local storage\n",
    "\n",
    "We store data in dictionnaries that map each leak source to its content, which is a dictionnary that maps each type of entity to the Dataframe containing its values. For example <b>d_sources[\"bahamas\"][\"officer\"]</b> is the Dataframe of officers coming from the bahamas leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_read_csv(filename) :\n",
    "    \"\"\" To have same rules when reading data from csv \"\"\"\n",
    "    return pd.read_csv(filename, dtype = str)\n",
    "\n",
    "def build_dict(source_name):\n",
    "    \"\"\"\n",
    "    Create a dictionnary for a certain source_name (among : Panama papers, Paradise papers...)\n",
    "    that maps to each entity name (among : Officer, Intermediary, Address...)\n",
    "    the content of the csv from source_name for this entity\n",
    "    \"\"\"\n",
    "    d = {en : my_read_csv(source_name + nodes_name + en + \".csv\") for en in usual_entity_names}\n",
    "    \n",
    "    if source_name == paradise_name: # Extra \"other\" entity in paradise papers\n",
    "        d[others_name] = my_read_csv(source_name + nodes_name + others_name + \".csv\")\n",
    "    \n",
    "    #Add edges\n",
    "    d[\"edges\"] = my_read_csv(source_name + edges_name + \".csv\")\n",
    "              \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dictionnary, that maps each source to its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sources = dict()\n",
    "d_sources[\"bahamas\"] = build_dict(bahamas_name)\n",
    "d_sources[\"panama\"] = build_dict(panama_name)\n",
    "d_sources[\"paradise\"] = build_dict(paradise_name)\n",
    "d_sources[\"offshore\"] = build_dict(offshore_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node_id', 'name', 'jurisdiction', 'jurisdiction_description',\n",
       "       'country_codes', 'countries', 'incorporation_date', 'inactivation_date',\n",
       "       'struck_off_date', 'closed_date', 'ibcRUC', 'status', 'company_type',\n",
       "       'service_provider', 'sourceID', 'valid_until', 'note'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sources['panama']['entity'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting familiar with the data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some coloring for printing\n",
    "\n",
    "Keep the same coloring during the project, it makes data very easily readable once you get familiar with the coloring !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mbahamas\u001b[0m\n",
      "\u001b[92mparadise\u001b[0m\n",
      "\u001b[91mpanama\u001b[0m\n",
      "\u001b[94moffshore\u001b[0m\n",
      "\u001b[1mUnknown source\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "BLUE = '\\033[94m'\n",
    "GREEN = '\\033[92m'\n",
    "YELLOW = '\\033[93m'\n",
    "RED = '\\033[91m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "color_dict = dict()\n",
    "color_dict[\"bahamas\"] = YELLOW\n",
    "color_dict[\"paradise\"] = GREEN\n",
    "color_dict[\"panama\"] = RED\n",
    "color_dict[\"offshore\"] = BLUE\n",
    "\n",
    "def color(str):\n",
    "    \"\"\"\n",
    "    Returns the str given in the color of the source it is from \n",
    "    (the str must contain source name)\n",
    "    \"\"\"\n",
    "    for source in color_dict.keys():\n",
    "        if source in str:\n",
    "            return color_dict[source] + str + END \n",
    "        \n",
    "    return BOLD + str + END #Default color is BOLD\n",
    "\n",
    "for name, _ in color_dict.items():\n",
    "    print(color(name))\n",
    "print(color(\"Unknown source\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what data source misses which column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "Node type address misses 10 columns, namely :  ['labels(n)', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type intermediary misses 10 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'company_type']\n",
      "Node type officer misses 11 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type entity misses 3 columns, namely :  ['labels(n)', 'address', 'type']\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "Node type address misses 10 columns, namely :  ['labels(n)', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type intermediary misses 11 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type officer misses 10 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'company_type']\n",
      "Node type entity misses 3 columns, namely :  ['labels(n)', 'address', 'type']\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[93mbahamas\u001b[0m\n",
      "Node type address misses 10 columns, namely :  ['labels(n)', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type intermediary misses 10 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'company_type']\n",
      "Node type officer misses 11 columns, namely :  ['labels(n)', 'address', 'jurisdiction_description', 'service_provider', 'jurisdiction', 'closed_date', 'incorporation_date', 'ibcRUC', 'type', 'status', 'company_type']\n",
      "Node type entity misses 3 columns, namely :  ['labels(n)', 'address', 'type']\n",
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "Node type entity misses 2 columns, namely :  ['inactivation_date', 'struck_off_date']\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "Node type intermediary misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[91mpanama\u001b[0m\n",
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "Node type entity misses 2 columns, namely :  ['inactivation_date', 'struck_off_date']\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "Node type officer misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[92mparadise\u001b[0m\n",
      "Node type officer misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[93mbahamas\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n",
      "Node type entity misses 2 columns, namely :  ['inactivation_date', 'struck_off_date']\n",
      "\n",
      " \u001b[91mpanama\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n",
      "\n",
      " \u001b[92mparadise\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n",
      "Node type intermediary misses 1 columns, namely :  ['status']\n",
      "\n",
      " \u001b[94moffshore\u001b[0m missing columns from source : \u001b[94moffshore\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for source, dict_data in d_sources.items():\n",
    "    for source_compare, dict_data_compare in d_sources.items():\n",
    "        print(\"\\n\", color(source_compare), \"missing columns from source :\", color(source))\n",
    "        for entity in usual_entity_names:\n",
    "            missing_columns = []\n",
    "            for col in dict_data[entity].columns:\n",
    "                if not col in dict_data_compare[entity].columns:\n",
    "                    missing_columns.append(col)\n",
    "            if(len(missing_columns) > 0):\n",
    "                print(\"Node type\", entity, \"misses\", len(missing_columns), \"columns, namely : \", missing_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that <span style=\"color:orange\">bahamas</span> is the most \"complete\" source, in the sense it is the one that has the biggest number of columns missing in the others. We will therefore use it to explore the content of columns. *'inactivation_date'* and  *'struck_off_date'* columns from entity will then be explored in <span style=\"color:red\">panama</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special case : Paradise paper, <i>other</i> node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node_id', 'name', 'country_codes', 'countries', 'sourceID',\n",
       "       'valid_until', 'note'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sources[\"paradise\"][\"other\"].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SourceID in different sources\n",
    "\n",
    "We see paradise papers is the only source that has different sourceID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source : \u001b[93mbahamas\u001b[0m\n",
      "Node : address 1 different sourceID :\n",
      "Node : intermediary 1 different sourceID :\n",
      "Node : officer 1 different sourceID :\n",
      "Node : entity 1 different sourceID :\n",
      "\n",
      "Source : \u001b[91mpanama\u001b[0m\n",
      "Node : address 1 different sourceID :\n",
      "Node : intermediary 1 different sourceID :\n",
      "Node : officer 1 different sourceID :\n",
      "Node : entity 1 different sourceID :\n",
      "\n",
      "Source : \u001b[92mparadise\u001b[0m\n",
      "Node : address 7 different sourceID :\n",
      "Node : intermediary 5 different sourceID :\n",
      "Node : officer 9 different sourceID :\n",
      "Node : entity 9 different sourceID :\n",
      "\n",
      "Source : \u001b[94moffshore\u001b[0m\n",
      "Node : address 1 different sourceID :\n",
      "Node : intermediary 1 different sourceID :\n",
      "Node : officer 1 different sourceID :\n",
      "Node : entity 1 different sourceID :\n"
     ]
    }
   ],
   "source": [
    "for source, dict_data in d_sources.items():\n",
    "    print(\"\\nSource :\", color(source))\n",
    "    for entity in usual_entity_names:\n",
    "        value_count =  dict_data[entity][\"sourceID\"].value_counts()\n",
    "        print(\"Node :\", entity, len(value_count), \"different sourceID :\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if node_id is a good index for Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_id isn't unique between nodes from source \u001b[94moffshore\u001b[0m\n",
      "node_id is unique between unique nodes from all sources\n"
     ]
    }
   ],
   "source": [
    "merged_node_id = pd.Series()\n",
    "\n",
    "for source, dict_data in d_sources.items():\n",
    "    merged_node_id_source = pd.Series()\n",
    "    for entity in usual_entity_names:\n",
    "        \n",
    "        merged_node_id_source = merged_node_id_source.append(dict_data[entity][\"node_id\"], ignore_index = True)\n",
    "        \n",
    "        if not dict_data[entity][\"node_id\"].is_unique:\n",
    "            print(\"node_id isn't unique for source\", color(source, \"node\", entity))\n",
    "                  \n",
    "    if not merged_node_id_source.is_unique:\n",
    "        print(\"node_id isn't unique between nodes from source\", color(source))\n",
    "    \n",
    "    merged_node_id = merged_node_id.append(merged_node_id_source.drop_duplicates())\n",
    "\n",
    "if merged_node_id.is_unique:\n",
    "    print(\"node_id is unique between unique nodes from all sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for each node type indepently node_id is a good index. Therefore (node_id, node_type) could be a good index (node_type being amond officer, intermediary...)\n",
    "\n",
    "Now explore nodes with same node_id in offshore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1maddress\u001b[0m \u001b[1mintermediary\u001b[0m\n",
      "\u001b[1maddress\u001b[0m \u001b[1mofficer\u001b[0m\n",
      "\u001b[1maddress\u001b[0m \u001b[1mentity\u001b[0m\n",
      "\u001b[1mintermediary\u001b[0m \u001b[1mofficer\u001b[0m\n",
      "Intersection of \u001b[1mintermediary\u001b[0m and \u001b[1mofficer\u001b[0m count is :\n",
      "name_intermediary             1139\n",
      "country_codes_intermediary    1139\n",
      "countries_intermediary        1139\n",
      "status                           0\n",
      "sourceID_intermediary         1139\n",
      "valid_until_intermediary      1139\n",
      "note_intermediary                0\n",
      "name_officer                  1139\n",
      "country_codes_officer         1139\n",
      "countries_officer             1139\n",
      "sourceID_officer              1139\n",
      "valid_until_officer           1139\n",
      "note_officer                     0\n",
      "dtype: int64\n",
      "\u001b[1mintermediary\u001b[0m \u001b[1mentity\u001b[0m\n",
      "\u001b[1mofficer\u001b[0m \u001b[1mentity\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(usual_entity_names)):\n",
    "    for j in range(i+1, len(usual_entity_names)):\n",
    "\n",
    "        left_node = usual_entity_names[i]\n",
    "        node = usual_entity_names[j]\n",
    "        print(color(left_node), color(node))\n",
    "        \n",
    "        if left_node != node:\n",
    "\n",
    "            left = d_sources[\"offshore\"][left_node].set_index(\"node_id\")\n",
    "            right = d_sources[\"offshore\"][node].set_index(\"node_id\")\n",
    "\n",
    "            intersection = left.join(right, on = \"node_id\", how = 'inner', \\\n",
    "                                     lsuffix = \"_\" + left_node,rsuffix = \"_\" + node)\n",
    "\n",
    "            if not intersection.empty:\n",
    "                print(\"Intersection of\", color(left_node), \"and\", color(node), \"count is :\")\n",
    "                print(intersection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the intersection on offshore is between officer and intermediary nodes. Let's see if they are the same values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = d_sources[\"offshore\"][\"officer\"].set_index(\"node_id\")\n",
    "right = d_sources[\"offshore\"][\"intermediary\"].set_index(\"node_id\")\n",
    "\n",
    "intersection = left.join(right, on = \"node_id\", how = 'inner', lsuffix = \"_officer\",rsuffix = \"_interm\")\n",
    "\n",
    "intersection.loc[intersection[\"name_officer\"] != intersection[\"name_interm\"]].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we understand that if someone appears in two different node types, it means it is the same person, but has two roles. This is why in further analysis we will store the pair (node_id, role) as index, because it is unique. We have to add a column to nodes, containing the node type, let's call it label. We saw in the column exploration that bahamas has an equivalent column *labels(n)*, that the other's don't, we'll rename it to *label*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep necessary columns, Shape data to our need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_clean = dict()\n",
    "\n",
    "#maps every node type to the columns to keep\n",
    "d_columns = dict()\n",
    "d_columns['address'] = ['country_codes', 'node_id']\n",
    "d_columns['entity'] = ['node_id','name','jurisdiction','incorporation_date']\n",
    "d_columns['intermediary'] = ['node_id', 'country_codes','name']\n",
    "d_columns['officer'] = ['node_id', 'country_codes','name']\n",
    "d_columns['other'] = ['node_id', 'country_codes','name']\n",
    "\n",
    "\n",
    "for source, d in d_sources.items():\n",
    "    \n",
    "    d_clean[source] = dict()\n",
    "    \n",
    "    for node_type in usual_entity_names:\n",
    "        d_clean[source][node_type] = d[node_type][d_columns[node_type]]\n",
    "        d_clean[source][node_type]['source'] = source\n",
    "        d_clean[source][node_type]['type'] = node_type\n",
    "        d_clean[source][node_type]['node_id'] = d_clean[source][node_type]['node_id'].astype(np.int32)\n",
    "    \n",
    "    columns_edges = ['START_ID', 'END_ID', 'TYPE', 'start_date', 'end_date']        \n",
    "    columns_edges_bahamas = ['node_1', 'node_2', 'rel_type', 'start_date', 'end_date']    \n",
    "    \n",
    "    if source == \"bahamas\": # adapt different column names\n",
    "        d_clean[source]['edges'] = d_sources[source]['edges'][columns_edges_bahamas]\n",
    "        d_clean[source]['edges'].columns = columns_edges\n",
    "        \n",
    "    else :\n",
    "        d_clean[source]['edges'] = d_sources[source]['edges'][columns_edges]\n",
    "    \n",
    "    d_clean[source]['edges']['source'] = source\n",
    "    d_clean[source]['edges'][\"START_ID\"] = d_clean[source]['edges'][\"START_ID\"].astype(np.int32)\n",
    "    d_clean[source]['edges'][\"END_ID\"] = d_clean[source]['edges'][\"END_ID\"].astype(np.int32) \n",
    "\n",
    "d_clean['paradise']['other'] = d_sources['paradise']['other'][d_columns['other']]\n",
    "d_clean[\"paradise\"]['other']['source'] = 'paradise'\n",
    "d_clean[\"paradise\"]['other']['type'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries for countries and jurisdictions\n",
    "\n",
    "These dictionaries map the abrevation of countries to their full name, this way we can drop the longer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = dict()\n",
    "jurisdictions = dict()\n",
    "\n",
    "for s in sources_names:\n",
    "    for t in usual_entity_names:\n",
    "        countries.update(dict(zip(d_sources[s][t]['country_codes'], d_sources[s][t]['countries'])))\n",
    "        if t  == 'entity':\n",
    "            jurisdictions.update(dict(zip(d_sources[s][t]['jurisdiction'], d_sources[s][t]['jurisdiction_description'])))\n",
    "            \n",
    "countries.update(dict(zip(d_sources['paradise']['other']['country_codes'],\\\n",
    "                          d_sources['paradise']['other']['countries'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and study *node* dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pourcentage function to print pourcentages in a nice way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pourcentage(n, precision = 2):\n",
    "    \"\"\" To print a pourcentage in a nice way and with a given precision\"\"\"\n",
    "    return color((\"%.\" + str(precision) + \"f\") % (100.0*n) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to convert string of date to datetime format. There are a LOT of different string formats and we cover most of them. Dates with ambiguity such as 01/03/2001 are treated arbitrarily. (i.e. is this date 1st of March or 3rd of January ?) Indeed the year is generally what matters the most for us.\n",
    "\n",
    "Years are valid until 2015 at most, and starting in the 1960s according to wikipedia (https://en.wikipedia.org/wiki/Panama_Papers)\n",
    "\n",
    "When date is clearly an outlier (18/19/2006), it is set to NaN, and printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date):\n",
    "    \"\"\" Parsing of the date, read above for more details\"\"\"\n",
    "    if (date==date):\n",
    "        try:\n",
    "            formatted = dateutil.parser.parse(date)\n",
    "            if (formatted.year > 2015 or formatted.year < 1960):\n",
    "                formatted = 'NaN'\n",
    "            return formatted \n",
    "        except:\n",
    "            print(date)\n",
    "            return 'NaN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node types that should contain NaN for each column name\n",
    "\n",
    "Nodes can have NaN values because of missing data, <b>or</b> because the data doesn't make sense for this node type. You will here find a list of node types for each column, those are node types that are NaN because of this second reason. For example the jurisdiction for an Officer doesn't really make sense at first sight... We will however in the future try to cumpute all the jurisdictions an officer is related to using the edges (and many more)\n",
    "\n",
    "##### name\n",
    "- Address\n",
    "\n",
    "##### jurisdiction and incorporation_date\n",
    "- Officer\n",
    "- Other\n",
    "- Intermediary\n",
    "- Address\n",
    "\n",
    "##### country_codes\n",
    "- Entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.DataFrame(columns=['node_id','source','type','name','country_codes', 'jurisdiction', 'incorporation_date'])\n",
    "\n",
    "for source,_ in d_sources.items():\n",
    "    for node_type in usual_entity_names:\n",
    "        nodes = nodes.append(d_clean[source][node_type], sort=False)\n",
    "        \n",
    "#nodes = nodes.append(d_clean['paradise']['other'], sort=False) # Uncomment to consider other nodes\n",
    "\n",
    "nodes = nodes.set_index(['node_id', 'type'])\n",
    "\n",
    "nodes['incorporation_date'] = nodes['incorporation_date'].apply(parse_date)\n",
    "nodes['incorporation_date'] = pd.to_datetime(nodes['incorporation_date'])\n",
    "\n",
    "nodes[nodes['country_codes'] == 'XXX'] = None\n",
    "nodes[nodes['jurisdiction'] == 'XXX'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>country_codes</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>incorporation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1813261</td>\n",
       "      <td>1438640</td>\n",
       "      <td>656715</td>\n",
       "      <td>731924</td>\n",
       "      <td>711888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>1176285</td>\n",
       "      <td>3570</td>\n",
       "      <td>79</td>\n",
       "      <td>15543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>paradise</td>\n",
       "      <td>THE BEARER</td>\n",
       "      <td>CHN</td>\n",
       "      <td>BAH</td>\n",
       "      <td>1998-01-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>864980</td>\n",
       "      <td>70871</td>\n",
       "      <td>69381</td>\n",
       "      <td>209634</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source        name country_codes jurisdiction   incorporation_date\n",
       "count    1813261     1438640        656715       731924               711888\n",
       "unique         4     1176285          3570           79                15543\n",
       "top     paradise  THE BEARER           CHN          BAH  1998-01-02 00:00:00\n",
       "freq      864980       70871         69381       209634                 1335\n",
       "first        NaN         NaN           NaN          NaN  1960-01-01 00:00:00\n",
       "last         NaN         NaN           NaN          NaN  2015-12-31 00:00:00"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are a lot of unique country_codes... Indeed we notice some nodes have many country codes separated by a ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4.26%\u001b[0m of nodes with a country_code have a country_code with more than one country\n"
     ]
    }
   ],
   "source": [
    "country_codes = nodes.country_codes.dropna()\n",
    "number_multi_country = country_codes[country_codes.str.contains(\";\")].count()\n",
    "\n",
    "print(pourcentage(number_multi_country/len(country_codes)), \"of nodes with a country_code have a country_code with more than one country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study by node type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>country_codes</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>incorporation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>731924</td>\n",
       "      <td>731895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>731924</td>\n",
       "      <td>711888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>702285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>15543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>paradise</td>\n",
       "      <td>DE PALM TOURS N.V. - DE PALM TOURS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAH</td>\n",
       "      <td>1998-01-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>290086</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209634</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source                                name  country_codes  \\\n",
       "count     731924                              731895            0.0   \n",
       "unique         4                              702285            0.0   \n",
       "top     paradise  DE PALM TOURS N.V. - DE PALM TOURS            NaN   \n",
       "freq      290086                                  19            NaN   \n",
       "first        NaN                                 NaN            NaN   \n",
       "last         NaN                                 NaN            NaN   \n",
       "\n",
       "       jurisdiction   incorporation_date  \n",
       "count        731924               711888  \n",
       "unique           79                15543  \n",
       "top             BAH  1998-01-02 00:00:00  \n",
       "freq         209634                 1335  \n",
       "first           NaN  1960-01-01 00:00:00  \n",
       "last            NaN  2015-12-31 00:00:00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.xs('entity', level = 1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>country_codes</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>incorporation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>681412</td>\n",
       "      <td>681395</td>\n",
       "      <td>384233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>478550</td>\n",
       "      <td>3509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>paradise</td>\n",
       "      <td>THE BEARER</td>\n",
       "      <td>MLT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>350001</td>\n",
       "      <td>70871</td>\n",
       "      <td>44916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source        name country_codes  jurisdiction  incorporation_date\n",
       "count     681412      681395        384233           0.0                 0.0\n",
       "unique         4      478550          3509           0.0                 0.0\n",
       "top     paradise  THE BEARER           MLT           NaN                 NaN\n",
       "freq      350001       70871         44916           NaN                 NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.xs('officer', level = 1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>country_codes</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>incorporation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25351</td>\n",
       "      <td>25350</td>\n",
       "      <td>22758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>24235</td>\n",
       "      <td>284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>panama</td>\n",
       "      <td>HUTCHINSON GAYLE A.</td>\n",
       "      <td>HKG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14110</td>\n",
       "      <td>62</td>\n",
       "      <td>4895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                 name country_codes  jurisdiction  \\\n",
       "count    25351                25350         22758           0.0   \n",
       "unique       4                24235           284           0.0   \n",
       "top     panama  HUTCHINSON GAYLE A.           HKG           NaN   \n",
       "freq     14110                   62          4895           NaN   \n",
       "\n",
       "        incorporation_date  \n",
       "count                  0.0  \n",
       "unique                 0.0  \n",
       "top                    NaN  \n",
       "freq                   NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.xs('intermediary', level = 1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>country_codes</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>incorporation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>374574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>paradise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>223325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source  name country_codes  jurisdiction  incorporation_date\n",
       "count     374574   0.0        249724           0.0                 0.0\n",
       "unique         4   0.0           215           0.0                 0.0\n",
       "top     paradise   NaN           CHN           NaN                 NaN\n",
       "freq      223325   NaN         31984           NaN                 NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.xs('address', level = 1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and study *edges* dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/19/2015\n",
      "16/20/2013\n",
      "05152015\n",
      "05152015\n",
      "05152015\n",
      "05152015\n",
      "05152015\n",
      "05152015\n",
      "05152015\n",
      "05152015\n",
      "1212012\n",
      "29/02/2006\n",
      "29/02/2006\n",
      "28.02/2014\n",
      "06/01.2009\n",
      "25090015\n",
      "31/02/2013\n",
      "31/02/2013\n",
      "31/02/2013\n",
      "12-112013\n",
      "284/2015\n"
     ]
    }
   ],
   "source": [
    "edges = pd.DataFrame(columns=['START_ID', 'END_ID', 'TYPE', 'start_date', 'end_date','source'])\n",
    "for source in sources_names:\n",
    "    edges = edges.append(d_clean[source]['edges'], sort=False)\n",
    "\n",
    "edges['start_date'] = pd.to_datetime(edges['start_date'].apply(parse_date))\n",
    "edges['end_date'] = pd.to_datetime(edges['end_date'].apply(parse_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printed strings are dates that were not read correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>START_ID</th>\n",
       "      <th>END_ID</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3142523.0</td>\n",
       "      <td>3142523.0</td>\n",
       "      <td>3142523</td>\n",
       "      <td>928670</td>\n",
       "      <td>266893</td>\n",
       "      <td>3142523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1054794.0</td>\n",
       "      <td>1224551.0</td>\n",
       "      <td>13</td>\n",
       "      <td>12353</td>\n",
       "      <td>8545</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>54662.0</td>\n",
       "      <td>236724.0</td>\n",
       "      <td>officer_of</td>\n",
       "      <td>1969-12-31 00:00:00</td>\n",
       "      <td>2012-09-30 00:00:00</td>\n",
       "      <td>paradise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>36373.0</td>\n",
       "      <td>37338.0</td>\n",
       "      <td>1667166</td>\n",
       "      <td>1848</td>\n",
       "      <td>9663</td>\n",
       "      <td>1657838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960-03-10 00:00:00</td>\n",
       "      <td>1960-05-30 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         START_ID     END_ID        TYPE           start_date  \\\n",
       "count   3142523.0  3142523.0     3142523               928670   \n",
       "unique  1054794.0  1224551.0          13                12353   \n",
       "top       54662.0   236724.0  officer_of  1969-12-31 00:00:00   \n",
       "freq      36373.0    37338.0     1667166                 1848   \n",
       "first         NaN        NaN         NaN  1960-03-10 00:00:00   \n",
       "last          NaN        NaN         NaN  2015-12-31 00:00:00   \n",
       "\n",
       "                   end_date    source  \n",
       "count                266893   3142523  \n",
       "unique                 8545         4  \n",
       "top     2012-09-30 00:00:00  paradise  \n",
       "freq                   9663   1657838  \n",
       "first   1960-05-30 00:00:00       NaN  \n",
       "last    2015-12-31 00:00:00       NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are <b>13</b> unique kind of edges, they are listed below. In further analysis it will be interesting to study each of them in more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['same_address_as', 'same_company_as', 'similar_company_as',\n",
       "       'intermediary_of', 'registered_address', 'same_name_as',\n",
       "       'same_intermediary_as', 'officer_of', 'probably_same_officer_as',\n",
       "       'connected_to', 'same_id_as', 'same_as', 'underlying'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.TYPE.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_edges = len(edges)\n",
    "number_start_date = edges.start_date.notna().sum()\n",
    "number_end_date = edges.end_date.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29.55%\u001b[0m of edges have a start date\n",
      "Among those, \u001b[1m22.32%\u001b[0m have an end date\n",
      "The first added relation was the 1960-03-10 00:00:00\n",
      "The last added relation was the 2015-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(pourcentage(number_start_date/number_edges), \"of edges have a start date\")\n",
    "print(\"Among those,\", pourcentage(number_end_date/(number_end_date+number_start_date)), \"have an end date\")\n",
    "print(\"The first added relation was the\", edges.start_date.min())\n",
    "print(\"The last added relation was the\", edges.start_date.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study average and extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.054794e+06\n",
      "mean     2.979277e+00\n",
      "std      6.123411e+01\n",
      "min      1.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      2.000000e+00\n",
      "max      3.637300e+04\n",
      "Name: START_ID, dtype: float64 \n",
      "\n",
      "count    1.224551e+06\n",
      "mean     2.566266e+00\n",
      "std      3.778810e+01\n",
      "min      1.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      2.000000e+00\n",
      "max      3.733800e+04\n",
      "Name: END_ID, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(edges.START_ID.value_counts().describe(), '\\n')\n",
    "print(edges.END_ID.value_counts().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that on average <b>2.98</b> edges start with the same node_id, and <b>2.57</b> end with the same node_id\n",
    "\n",
    "Max number of connections starting from a given node is <b>36373</b>, and <b>37338</b> ending (another node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study connection between edges and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_max_links_start = edges.START_ID.value_counts().idxmax()\n",
    "max_links_start = edges.START_ID.value_counts().max()\n",
    "node_max_links_start = nodes.xs(id_max_links_start, level=0)\n",
    "\n",
    "id_max_links_end = edges.END_ID.value_counts().idxmax()\n",
    "max_links_end = edges.END_ID.value_counts().max()\n",
    "node_max_links_end = nodes.xs(id_max_links_end, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Node with the most START edges has \u001b[1m36373\u001b[0m links and is :\n",
      "                source                               name    country_codes\n",
      "type                                                                      \n",
      "intermediary  offshore  Portcullis TrustNet (BVI) Limited  THA;VGB;IDN;SGP\n",
      "officer       offshore  Portcullis TrustNet (BVI) Limited  THA;VGB;IDN;SGP\n",
      "\n",
      "The Node with the most END edges has \u001b[1m37338\u001b[0m links and is :\n",
      "           source country_codes\n",
      "type                           \n",
      "address  offshore           VGB\n"
     ]
    }
   ],
   "source": [
    "print(\"The Node with the most START edges has\", color(str(max_links_start)), \"links and is :\")\n",
    "print(node_max_links_start[['source', 'name', 'country_codes']])\n",
    "\n",
    "print(\"\\nThe Node with the most END edges has\", color(str(max_links_end)), \"links and is :\")\n",
    "print(node_max_links_end[['source', 'country_codes']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful sets for the following study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_nodes = set(edges.START_ID)\n",
    "end_nodes = set(edges.END_ID)\n",
    "\n",
    "nodes_address_ids = set(nodes.xs('address', level='type').index.values)\n",
    "nodes_officer_ids = set(nodes.xs('officer', level='type').index.values)\n",
    "nodes_entity_ids = set(nodes.xs('entity', level='type').index.values)\n",
    "nodes_intermediary_ids = set(nodes.xs('intermediary', level='type').index.values)\n",
    "\n",
    "d_nodes_ids = {\n",
    "    'address': nodes_address_ids,\n",
    "    'officer': nodes_officer_ids,\n",
    "    'entity' : nodes_entity_ids,\n",
    "    'intermediary' : nodes_intermediary_ids\n",
    "}\n",
    "\n",
    "node_ids = frozenset().union(*d_nodes_ids.values())\n",
    "\n",
    "linked_nodes = start_nodes.union(end_nodes)\n",
    "isolated_nodes = node_ids.difference(linked_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study nodes that are isolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are \u001b[1m358\u001b[0m isolated nodes (0 edge connecting them)\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", color(str(len(isolated_nodes))), \"isolated nodes (0 edge connecting them)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>country_codes</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>incorporation_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>334</td>\n",
       "      <td>318</td>\n",
       "      <td>42</td>\n",
       "      <td>160</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>297</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>panama</td>\n",
       "      <td>THE BEARER</td>\n",
       "      <td>GBR</td>\n",
       "      <td>KNA</td>\n",
       "      <td>1998-12-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>167</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-08-05 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source        name country_codes jurisdiction   incorporation_date\n",
       "count      334         318            42          160                  134\n",
       "unique       3         297            23            2                  107\n",
       "top     panama  THE BEARER           GBR          KNA  1998-12-04 00:00:00\n",
       "freq       167          21             7          149                    5\n",
       "first      NaN         NaN           NaN          NaN  1985-09-23 00:00:00\n",
       "last       NaN         NaN           NaN          NaN  2011-08-05 00:00:00"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_isolated = nodes.index.get_level_values(0).isin(isolated_nodes)\n",
    "nodes[mask_isolated].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning\n",
    "\n",
    "We are planning to infer using the edges:\n",
    "- all the jurisdictions some nodes such as *officer* have links to, in order to see if see if they are connected to accounts in different jurisdictions.\n",
    "- for *entity* the country_codes, which would be the country of the people that are connected to this jurisdiction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add all content to edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-7a156169c97d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmerge_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start_country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start_jurisdiction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0medges_completed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'START_ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmerge_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end_country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end_jurisdiction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   6387\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6388\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6389\u001b[0;31m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[1;32m   6390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m             elif (not is_numeric_dtype(lk)\n\u001b[1;32m    985\u001b[0m                     and (is_numeric_dtype(rk) and not is_bool_dtype(rk))):\n\u001b[0;32m--> 986\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "merge_nodes = nodes.reset_index()[['node_id', 'type', 'country_codes', 'jurisdiction']]\n",
    "merge_nodes.columns = ['id', 'start_type', 'start_country', 'start_jurisdiction']\n",
    "\n",
    "edges_completed = edges.merge(merge_nodes, how = 'left', left_on='START_ID', right_on='id')\n",
    "\n",
    "merge_nodes.columns = ['id', 'end_type', 'end_country', 'end_jurisdiction']\n",
    "\n",
    "edges_completed = edges_completed.merge(merge_nodes, how = 'left', left_on='END_ID', right_on='id')\n",
    "\n",
    "edges_completed = edges_completed.drop(columns = ['id_x', 'id_y'])\n",
    "\n",
    "edges_completed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.xs('other', level='type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2) Do people that are related to one offshore account tend to be related to many more? In other words, is it more likely to have another account once you already have one, than it is to have at least one account?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_officer_to_entity = (edges_completed['start_type'] == 'officer') & (edges_completed['end_type'] == 'entity')\n",
    "\n",
    "edges_officer_to_entity = edges_completed[mask_officer_to_entity]\n",
    "entities_per_officer = edges_officer_to_entity['START_ID'].value_counts()\n",
    "\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.hist(entities_per_officer, bins=[1, 2, 10, 100, 1000, 10000, 100000], histtype='step', log = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *5) Is there a correlation between the location of the people and the location of their offshore society?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges_completed[(edges_completed['start_country'] != edges_completed['end_country']) \\\n",
    "               & (edges_completed['start_country'].notna()) & ((edges_completed['end_country'].notna()))]\\\n",
    ".TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_completed[(edges_completed['start_jurisdiction'] != edges_completed['end_jurisdiction']) \\\n",
    "               & (edges_completed['start_jurisdiction'].notna()) & ((edges_completed['end_jurisdiction'].notna()))]\\\n",
    ".TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the type of START nodes and of END nodes to see if there is a logic (entity always START node etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we consider the ones not leading to entity as outliers and withdraw them ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges_completed[edges_completed['end_type'] == 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_completed[edges_completed['start_type'] == 'other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO : column link is more precise (shareholder of) just not there in bahamas\n",
    "## Should be added with NaN if not there\n",
    "## There is no edge between 'other' nodes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of start/end nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_start_node = nodes.index.get_level_values(0).isin(start_nodes)\n",
    "mask_end_node = nodes.index.get_level_values(0).isin(end_nodes)\n",
    "\n",
    "start_nodes_type = nodes[mask_start_node].index.get_level_values(\"type\").tolist()\n",
    "end_nodes_type = nodes[mask_end_node].index.get_level_values(\"type\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(start_nodes_type).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Address is (almost) never an end node (makes sense condsidering the name of edge is \"address of\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(end_nodes_type).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So intermediary is (almost) never an end node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity is the only node type to have jurisdiction, we need to link every entity with the other nodes that do contain a country_code. Let's see first if connected components always have the one country_code, and if not quantify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_officer_to_entity[edges_officer_to_entity['TYPE'] == 'officer_of']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use slicers to access a set of values on index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
